{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e063ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc55409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a751be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0872b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c276731",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "stops.remove('not')\n",
    "stops.remove('no')\n",
    "stops.remove('very')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b92de",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback = pd.read_excel(r'C:\\Users\\Saurabh Mulgaonkar\\Jupyter_Notebooks\\IT_Vedant_Files\\Projects\\Final_Project\\Python_Files\\cleaned_data\\feedback_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f471f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to str (type error observed)\n",
    "df_feedback['Feedback'] = df_feedback['Feedback'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"\\n\" specifically \n",
    "def remove_slash_n(text):\n",
    "    return text.replace('\\\\n',' ')\n",
    "\n",
    "# remove only newlines\n",
    "def remove_newline(text):\n",
    "    return re.sub(\"\\s\",\" \",text)\n",
    "\n",
    "# keep only alphabets, remove digits, extra chars, except-> .!?\n",
    "#def keep_alpha_only(text):\n",
    "#    return re.sub(\"[^a-zA-Z.!?]\",\" \",text)\n",
    "\n",
    "# keep only alphabets\n",
    "def keep_alpha_only(text):\n",
    "    return re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "\n",
    "# lower case \n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "#remove extra full stops, exclamations, question marks\n",
    "#def remove_extra_fs(text):\n",
    "#    return re.sub(\"[.!?]{2}\",\" \",text)\n",
    "\n",
    "#  remove specific cases \n",
    "def remove_sp_case(text):\n",
    "    text = text.replace('gcxxc',' ')\n",
    "    text = text.replace('cxxxx',' ')\n",
    "    text = text.replace('xxxxx',' ')\n",
    "    text = text.replace('xxnsnokjsd',' ')\n",
    "    text = text.replace('xxxxxx',' ')\n",
    "    text = text.replace('asxxx',' ')\n",
    "    text = text.replace('xxxx xxxx',' ')\n",
    "    text = text.replace('xx vv',' ')\n",
    "    text = text.replace('xxxxxxx',' ')\n",
    "    text = text.replace('thnxx',' ')\n",
    "    text = text.replace('exxperience','experience')\n",
    "    text = text.replace('exxcellent','excellent')\n",
    "    text = text.replace('pro maxx','great')\n",
    "    text = text.replace('xx',' ')\n",
    "    text = text.replace('good g bm j xx','good')\n",
    "    return text\n",
    "\n",
    "# trim text\n",
    "def trim(text):\n",
    "    return text.strip()\n",
    "\n",
    "def word_tokenize(text):\n",
    "    return text.split(' ')\n",
    "\n",
    "#def remove_gibberish(list_text):\n",
    "#    for word in list_text:\n",
    "#        if word not in words.words():\n",
    "#            list_text.remove(word)\n",
    "#    return list_text\n",
    "    \n",
    "def stop_word_removal(list_text):\n",
    "    filter_stop = [word for word in list_text if word not in stops]\n",
    "    return \" \".join(filter_stop)\n",
    "\n",
    "#def stem(list_text):\n",
    "#    stem=[]\n",
    "#    for word in list_text:\n",
    "#        stem.append(s_stemmer.stem(word))\n",
    "#    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cafdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def clean_text(text):\n",
    "    text = remove_slash_n(text)\n",
    "    text = remove_newline(text)\n",
    "    text = keep_alpha_only(text)\n",
    "    text = lower(text)\n",
    "    text = remove_sp_case(text)\n",
    "    text = trim(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4160c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['Feedback'].apply(lambda x:clean_text(x))#.to_csv('check4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2164343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['clean_text'] = df_feedback['Feedback'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback[df_feedback['Feedback'].str.lower()==\"pro maxx\"]\n",
    "# change pro maxx to great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c92f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = df_feedback[df_feedback['clean_text']==''].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.drop(idx1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['tokenize'] = df_feedback['clean_text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37c412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for token in test1:\n",
    "#    print(f'Token: {str(token)}')\n",
    "#    print(f'TAG: {token.tag_},         POS: {token.pos_}')\n",
    "#    print(f'Explanation: {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    pos ={}\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        pos[str(token)] = token.pos_\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['pos2'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31bdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos(start,end,step):\n",
    "    # for the first 1 lac records - create steps\n",
    "    p1 = list(range(start,end+1,step))\n",
    "    p2 = list(range(start+step,end+1+step,step))\n",
    "    print(p1)\n",
    "    print(p2)\n",
    "    \n",
    "    for beg, last in zip(p1,p2):\n",
    "        df_feedback['pos2'].iloc[beg:last] = df_feedback['stop_word_removed'][beg:last].apply(pos_tagging)\n",
    "        print(f'Done till {last}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab02bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_pos(0,100000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f637c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(110000,200000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987188c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(210000,300000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(310000,400000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b63aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(410000,500000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e22c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(510000,600000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcccc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(610000,690000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pos(700000,708253,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fa146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "#df_feedback.to_pickle('feedback.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7eae5",
   "metadata": {},
   "source": [
    "**--------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9c33d",
   "metadata": {},
   "source": [
    "**VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback = pd.read_pickle('feedback.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b34ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['pos'].to_pickle('pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbeb5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_feedback.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78535ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobj = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classification(text,sentiment_analyzer):\n",
    "    temp_dict = sentiment_analyzer.polarity_scores(text)\n",
    "    score = temp_dict['compound']\n",
    "    \n",
    "    if score >= 0.05:\n",
    "        return 'Positive'\n",
    "    \n",
    "    elif score <= -0.05:\n",
    "        return 'Negative'\n",
    "    \n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['clean_text'].loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['sentiment'] = df_feedback['clean_text'].apply(lambda x: sentiment_classification(x,sobj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93244bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d1d05",
   "metadata": {},
   "source": [
    "**More Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback['stop_word_removed'] = df_feedback['tokenize'].apply(stop_word_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback = pd.read_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.to_csv('check_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d501dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback.to_csv('check2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c931db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "#df_feedback.to_pickle('feedback3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9903b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback.drop('pos',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504e77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd7410",
   "metadata": {},
   "source": [
    "**Summary Phrases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff65d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feedback = pd.read_pickle('feedback5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65d9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13159eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#def extract_phrases(text):\\n    \\n    patt=\\'\\'\\n    doc = nlp(text)\\n    \\n    #first pattern adj, noun\\n    pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}]\\n    matcher.add(\"FULL_NAME\", [pattern])\\n    matches = matcher(doc)\\n    for _, start, end in matches:\\n        span = doc[start:end]\\n        patt = span.text\\n    \\n    if patt==\\'\\':\\n        pattern = [{\"POS\": \"ADJ\"}]\\n        matcher.add(\"FULL_NAME\", [pattern])\\n        matches = matcher(doc)\\n        for _, start, end in matches:\\n            span = doc[start:end]\\n            patt = span.text\\n        \\n    \\n    return patt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#def extract_phrases(text):\n",
    "    \n",
    "    patt=''\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #first pattern adj, noun\n",
    "    pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}]\n",
    "    matcher.add(\"FULL_NAME\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "    for _, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        patt = span.text\n",
    "    \n",
    "    if patt=='':\n",
    "        pattern = [{\"POS\": \"ADJ\"}]\n",
    "        matcher.add(\"FULL_NAME\", [pattern])\n",
    "        matches = matcher(doc)\n",
    "        for _, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            patt = span.text\n",
    "        \n",
    "    \n",
    "    return patt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ca039a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrases(text):\n",
    "    \n",
    "    patt=''\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #first pattern adj, noun\n",
    "    pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\"}]\n",
    "    matcher.add(\"FULL_NAME\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "    for _, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        patt = span.text\n",
    "    \n",
    "    if patt=='':\n",
    "        pattern = [{\"POS\": \"ADJ\"},{\"POS\": \"NOUN\"}]\n",
    "        matcher.add(\"FULL_NAME\", [pattern])\n",
    "        matches = matcher(doc)\n",
    "        for _, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            patt = span.text\n",
    "        \n",
    "    \n",
    "    return patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26b2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['clean_text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffff3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['clean_text'][:100].apply(extract_phrases).to_csv('3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ae4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['Summary'] = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e94394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_feedback['Feedback'][df_feedback['stop_word_removed']==\"\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99ce7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lst_positive = ['1to10','9to10','A+++++','10 out of 10','9 to 10','5out of 5 ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f5bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1to10\n",
    "# 9to10\n",
    "# A+++++\n",
    "# 10 out of 10\n",
    "# 9 to 10\n",
    "# '5out of 5 '\n",
    "\n",
    "#df_feedback['sentiment'][df_feedback['Feedback'].isin(lst_positive)] = 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be093220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phrase_ser(start,end,step):\n",
    "    # for the first 1 lac records - create steps\n",
    "    p1 = list(range(start,end+1,step))\n",
    "    p2 = list(range(start+step,end+1+step,step))\n",
    "    print(p1)\n",
    "    print(p2)\n",
    "    \n",
    "    for beg, last in zip(p1,p2):\n",
    "        df_feedback['Summary'].iloc[beg:last] = df_feedback['clean_text'][beg:last].apply(extract_phrases)\n",
    "        print(f'Done till {last}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de16c114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000]\n",
      "[10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000]\n",
      "Done till 10000\n",
      "Done till 20000\n",
      "Done till 30000\n",
      "Done till 40000\n",
      "Done till 50000\n",
      "Done till 60000\n",
      "Done till 70000\n",
      "Done till 80000\n",
      "Done till 90000\n",
      "Done till 100000\n",
      "Done till 110000\n"
     ]
    }
   ],
   "source": [
    "create_phrase_ser(0,100000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe61ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback = pd.read_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e09f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d01f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['Summary'].value_counts().to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff82f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feedback['clean_text'][:100].apply(extract_phrases).to_csv('5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e4cfdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000]\n",
      "[120000, 130000, 140000, 150000, 160000, 170000, 180000, 190000, 200000, 210000]\n",
      "Done till 120000\n",
      "Done till 130000\n",
      "Done till 140000\n",
      "Done till 150000\n",
      "Done till 160000\n",
      "Done till 170000\n",
      "Done till 180000\n",
      "Done till 190000\n",
      "Done till 200000\n",
      "Done till 210000\n"
     ]
    }
   ],
   "source": [
    "create_phrase_ser(110000,200000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15078b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad8c628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210000, 220000, 230000, 240000, 250000, 260000, 270000, 280000, 290000, 300000]\n",
      "[220000, 230000, 240000, 250000, 260000, 270000, 280000, 290000, 300000, 310000]\n",
      "Done till 220000\n",
      "Done till 230000\n",
      "Done till 240000\n",
      "Done till 250000\n",
      "Done till 260000\n",
      "Done till 270000\n",
      "Done till 280000\n",
      "Done till 290000\n",
      "Done till 300000\n",
      "Done till 310000\n"
     ]
    }
   ],
   "source": [
    "create_phrase_ser(210000,300000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65077dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106ad684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310000, 320000, 330000, 340000, 350000, 360000, 370000, 380000, 390000, 400000]\n",
      "[320000, 330000, 340000, 350000, 360000, 370000, 380000, 390000, 400000, 410000]\n",
      "Done till 320000\n",
      "Done till 330000\n",
      "Done till 340000\n",
      "Done till 350000\n",
      "Done till 360000\n",
      "Done till 370000\n",
      "Done till 380000\n",
      "Done till 390000\n",
      "Done till 400000\n",
      "Done till 410000\n"
     ]
    }
   ],
   "source": [
    "create_phrase_ser(310000,400000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c965788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[410000, 420000, 430000, 440000, 450000, 460000, 470000, 480000, 490000, 500000]\n",
      "[420000, 430000, 440000, 450000, 460000, 470000, 480000, 490000, 500000, 510000]\n",
      "Done till 420000\n",
      "Done till 430000\n",
      "Done till 440000\n",
      "Done till 450000\n",
      "Done till 460000\n",
      "Done till 470000\n",
      "Done till 480000\n",
      "Done till 490000\n"
     ]
    }
   ],
   "source": [
    "create_phrase_ser(410000,500000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_phrase_ser(510000,600000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b369b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_phrase_ser(610000,690000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec3e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_phrase_ser(700000,708253,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results into a pkl file\n",
    "df_feedback.to_pickle('feedback6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe93fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
